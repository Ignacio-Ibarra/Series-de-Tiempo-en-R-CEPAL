---
title: "Herramientas para el An√°lisis de Series de Tiempo en R - Clase 2"
author: "Oficina de la CEPAL en Buenos Aires"
date: "Octubre 2021"
output:
  prettydoc::html_pretty:
    theme: architect
    fig_height: 5
    fig_width: 8
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
  html_notebook:
    code_folding: show
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
library(prettydoc)
```

```{r, include=FALSE}

##  Limpiar la memoria
rm(list=ls())

## Apertura de librerias
library(tidyverse)  #Manejo de bases de datos y otros
library(openxlsx)   #Lectura de xlsx
library(lubridate)  #Manejo de variables en formato fecha
library(zoo)        #Series de tiempo
library(forecast)   #Pronosticos
library(ggfortify)  #Graficos
library(kableExtra)

```

# Introducci√≥n

En esta segunda clase vamos a hacer un repaso del modelo lineal y de su estimaci√≥n a partir del m√©todo de m√≠nimos cuadrados ordinarios (MCO), vamos a interpretar los resultados de la regresi√≥n, y vamos a ver un conjunto de m√©tricas para seleccionar el modelo que mejor ajusta a una determinada muestra de datos.

Luego, en el m√≥dulo pr√°ctico, aprenderemos c√≥mo realizar estimaciones por MCO con R, y c√≥mo obtener las m√©tricas vistas en el m√≥dulo conceptual.


# M√≥dulo conceptual

## Modelo lineal

En el modelo de regresi√≥n m√°s simple se establece una relaci√≥n lineal entre dos variables, en la cual se desea explicar c√≥mo var√≠a una de ellas ($y$) en funci√≥n de la variaci√≥n de la otra ($x$). 

\begin{align*}
ùë¶=\beta_{0}+\beta_{1}x+u \\
\end{align*}

Donde:

$y$: Variable explicada o dependiente.

$x$: Variable explicativa o independiente.

$u$: T√©rmino de error (factores distintos a $x$ que a afectan a $y$, y que son no observables).

$\beta_{0}$: constante o intercepto.

$\beta_{1}$: par√°metro de la pendiente en la relaci√≥n entre $x$ y $y$, cuando todos los dem√°s factores en $u$ permanecen constantes.

Si los dem√°s factores en ùíñ permanecen constantes, de manera que el cambio en $u$ sea cero, entonces $x$ tiene un efecto lineal sobre $y$:

\begin{align*}
\Delta y=\beta_{1}\Delta x  \ si \  \Delta u=0 \\
\end{align*}

Por tanto, el cambio en $y$ es $\beta_{1}$ multiplicado por el cambio en $x$. Esto significa que $\beta_{1}$ es el par√°metro de la pendiente en la relaci√≥n entre $y$ y $x$, cuando todos los dem√°s factores en ùíñ permanecen constantes. Este es el par√°metro de inter√©s primordial.

La linealidad de la ecuaci√≥n implica que todo cambio en $x$ tiene siempre el mismo efecto sobre $y$, sin importar el valor inicial de $x$. Notar que nos estamos refiriendo a la linealidad de los par√°metros y no a la forma funcional de las variables. No obstante, en muchas aplicaciones de la econom√≠a la linealidad de los par√°metros no es un supuesto realista. Por este motivo hay estrategias para abordar estas situaciones, que incluyen las interacciones y las estimaciones por umbrales.


### Supuesto para asumir relaci√≥n *ceteris paribus*: media condicional cero
Un supuesto de vital importancia para poder formular conclusiones *ceteris paribus* acerca de c√≥mo afecta $x$ a $y$ (en una muestra aleatoria), es el de media condicional cero.

\begin{align*}
E(u|x)=0  \\
\end{align*}

El supuesto de media condicional cero proporciona otra interpretaci√≥n de $\beta_{1}$:

\begin{align*}
ùê∏(y|x)=\beta_{0}+\beta_{1}x \\
\end{align*}

La ecuaci√≥n muestra que en la funci√≥n de regresi√≥n poblacional (FRP), $ùê∏(ùë¶|ùë•)$ es una funci√≥n lineal de $x$. La linealidad significa que por cada aumento de una unidad en $x$ el valor esperado de $y$ se modifica en la cantidad $\beta_{1}$. Dado cualquier valor de $x$, la distribuci√≥n de $y$ est√° centrado en $ùê∏(ùë¶|ùë•)$.

**Importante:** Esta ecuaci√≥n dice c√≥mo var√≠a el valor promedio de $y$ de acuerdo con la variaci√≥n de $x$, y  no dice que $ùíö$ sea igual a $\beta_{0}+\beta_{1}x$ para cada valor de la poblaci√≥n. 


### Condiciones para asumir media condicional cero

**1. La media del error en la poblaci√≥n es cero.** Esto se obtiene directamente de incluir el intercepto en la regresi√≥n, y no requiere de asumir una determinada relaci√≥n entre las variables.

\begin{align*}
ùê∏(ùë¢)=0 \\
\end{align*}

**2. El valor esperado de $ùíñ$ no depende del valor de $x$.** Este supuesto indica que el valor promedio de los factores no observables es el mismo en todas las fracciones de la poblaci√≥n determinados por los valores de $ùë•$ y que este promedio com√∫n es necesariamente igual al promedio de $ùë¢$ en toda la poblaci√≥n.

\begin{align*}
ùê∏(ùë¢|ùë•)=ùê∏(ùë¢) \\
\end{align*}


## M√≠nimos Cuadrados Ordinarios (MCO)

### Condiciones de primer orden

Para obtener los estimadores del intercepto ($\beta_{0}$) y de la pendiente de la funci√≥n de regresi√≥n poblacional ($\beta_{1}$), el m√©todo de m√≠nimos cuadrados ordinarios parte de los dos supuestos anteriores (conocidos como condiciones de primer orden):

**1. La esperanza del t√©rmino de error es igual a cero**

\begin{align*}
ùê∏(ùë¢)=0 \\
\end{align*}


**2. El t√©rmino de error no est√° correlacionado con ùíô en la poblaci√≥n**

\begin{align*}
ùê∂ùëúùë£(ùë•,ùë¢)=ùê∏(ùë•ùë¢)=0 \\
\end{align*}


Partiendo de estos supuestos es posible derivar estimadores de los par√°metros poblacionales que minimicen la suma de residuales cuadrados. 


A los fines de simplificar la interpretaci√≥n presentamos los estimadores para un modelo univariado:

**Funci√≥n de regresi√≥n poblacional (FRP):**

$ùê∏(ùë¶|ùë•)=ùõΩ_{0}+ùõΩ_{1} ùë•$

**Funci√≥n de regresi√≥n muestral (FRM):**

$\hat{y}=\hat{ùõΩ}_{0}+\hat{ùõΩ}_{1} ùë•$

**Pendiente de la FRM:**

$\hat{ùõΩ}_{1}=\frac{\sum_{i=1}^{n}(x_{i}-\overline{x})(y_{i}-\overline{y})}{\sum_{i=1}^{n}(x_{i}-\overline{x})^{2}}$

**Intercepto de la FRM:**

$\hat{ùõΩ}_{0}=\overline{y}-\hat{ùõΩ}_{1} \overline{x}$


### Desv√≠o est√°ndar de los par√°metros y del residuo

El desv√≠o est√°ndar de los par√°metros y del residuo son fundamentales para poder realizar una inferencia estad√≠stica sobre los par√°metros poblacionales, tanto a partir de la obtenci√≥n de los intervalos de confianza, como de las pruebas de hip√≥tesis. En la medida que se conozca su distribuci√≥n, un menor desv√≠o est√°ndar nos permitir√° obtener estimaciones m√°s precisas de los par√°metros. Esto se reflejar√° en que obtendremos intervalos de confianza m√°s estrechos y que ser√° menor la probabilidad de no rechazar la hip√≥tesis nula del test de hip√≥tesis ante la presencia de par√°metros distintos a cero (siempre que esa sea nuestra hip√≥tesis nula).

Las varianzas de los estimadores y del residuo se definen de la siguiente forma:

**Varianza de $\beta_{1}$**:

\begin{align*}
\hat{\sigma}_{\beta_{1}}^{2}=Var(\hat{\beta_{1}})=\frac{\hat{\sigma}^{2}}{\sum_{i=1}^{n}(x_{i}-\overline{x})^{2}} \\
\end{align*}

**Varianza del error**:

\begin{align*}
\hat{\sigma}^{2}=\frac{1}{n-2}\sum_{=1}^{ùëõ}\hat{u}_{i}^{2} \\
\end{align*}

* **En el t√©rmino del error se prefiere una menor variabilidad**: cuanto mayor sea la varianza del error ($\hat{\sigma}^{2}$), mayor es $\hat{\sigma}_{\beta_{1}}^{2}$. Es decir que, a una mayor variaci√≥n en los factores no observables que afectan a $ùë¶$, m√°s dif√≠cil es estimar $\beta_{1}$ con precisi√≥n.

* **En la variable independiente se prefiere una mayor variabilidad**: a medida que aumenta la variabilidad de las $ùë•_{ùëñ}$ la varianza de $\hat{\beta}_{1}$ disminuye. Esto es as√≠ porque cuanto m√°s dispersa sea la muestra de las variables independientes, m√°s f√°cil ser√° hallar la relaci√≥n entre $ùê∏(ùë¶|ùë•)$ y $ùë•$. Es decir, ser√° m√°s sencillo estimar $ùõΩ_{1}$. Si hay poca variaci√≥n en las $ùë•_{i}$, entonces puede ser dif√≠cil hallar c√≥mo var√≠a $ùê∏(ùë¶|ùë•)$ con la variaci√≥n en $ùë•$.

* A medida que se incrementa el tama√±o de la muestra, tambi√©n aumenta la variaci√≥n total de las $ùë•_{ùëñ}$. Por este motivo es que siempre se busca que el tama√±o de la muestra sea lo m√°s grande posible.

#### Estimar intervalos de confianza

Una primera utilidad de la varianza y del desv√≠o est√°ndar de los estimadores y del residuo es calcular los intervalos de confianza. A continuaci√≥n se presenta un ejemplo para un modelo univariado con un nivel de confianza del 95% (percentil 97,5% de una distribuci√≥n t de Student).

Intervalo de confianza para los **estimadores**:

\begin{align*}
\hat{\beta_{1}}¬±1,96 \hat{\sigma}_{\beta_{1}} \\
\end{align*}

Intervalo de confianza para la **variable dependiente**:

\begin{align*}
\hat{y_{1}}¬±1,96 \hat{\sigma} \\
\end{align*}

**Regla del pulgar**: como el estad√≠stico al 95% de confianza es 1,96, a veces se suele hacer un c√°lculo m√°s sencillo que consiste en sumar y restar 2 desv√≠os est√°ndar a la estimaci√≥n puntual para obtener los intervalos de confianza.


#### Test de hip√≥tesis

Una segunda utilidad consiste en realizar un test de hip√≥tesis sobre el valor de los par√°metros poblaciones desconocidos.

En la mayor√≠a de las aplicaciones, el inter√©s principal reside en probar la hip√≥tesis nula:

\begin{align*}
ùêª_{0}:ùõΩ_{1}=0 \\
\end{align*}

El estad√≠stico que se emplea para probar la hip√≥tesis nula se llama el estad√≠stico t de $ùõΩ_{1}$ y se define como:

\begin{align*}
ùë°_{\hat{\beta}_{1}}=\frac{\hat{\beta}_{1}}{\hat{\sigma}_{\beta_{1}}} \\
\end{align*}

La regla de rechazo para $ùêª_{0}$: $\beta_{1}=0$ es:

\begin{align*}
|ùë°_{ùõΩ} |>ùëê \\
\end{align*}

Donde $c$ es un valor cr√≠tico elegido de manera aproximada. Para determinar $c$ se especifica un nivel de significatividad, el cual puede ser interpretado como la probabilidad de rechazar la hip√≥tesis nula cuando en realidad es verdadera. El nivel de significatividad m√°s usado es del 5%, y el valor cr√≠tico asociado es 1,96.

#### P-valor

El procedimiento cl√°sico del test de hip√≥tesis consiste en elegir un valor cr√≠tico con un nivel de significatividad arbitrario y compararlo con el valor del estad√≠stico t. Con eso se determina el rechazo o no de la hip√≥tesis nula.

Un procedimiento alternativo consiste en responder a la siguiente pregunta: **dado el valor observado del estad√≠stico t, ¬øcu√°l es el menor nivel de significatividad al que se habr√≠a rechazado la hip√≥tesis nula?** Este nivel se conoce como el p-valor.

Para obtenerlo se resta 100 al percentil correspondiente al valor t y se lo multiplica por 2 (para el test de dos colas). Cuanto menor sea el p-valor, mayor evidencia habr√° para rechazar la hip√≥tesis nula. Si, por ejemplo, el p-valor es menor a 0,05 tendremos evidencia para rechazar la hip√≥tesis nula a un nivel de significatividad del 5%, y por tanto tendremos evidencia a favor (aunque no necesariamente conclusiva) de que el valor del par√°metro poblacional es distinto a cero.


### R-cuadrado

El R2 es la m√©trica m√°s utilizada para medir qu√© tan bien ajusta el modelo a la muestra. Este se calcula como el cociente entre la variaci√≥n explicada y la variaci√≥n total, y por este motivo se interpreta como la proporci√≥n de la variaci√≥n muestral de $ùë¶$ que es explicada por $ùë•$.

\begin{align*}
ùëÖ^2=ùëÜùê∏ùê∂/ùëÜùëáùê∂=1‚àíùëÜùëÖùê∂/ùëÜùëáùê∂ \\
\end{align*}


Donde

Suma total de cuadrados (STC): $\sum_{ùëñ=1}^{ùëõ}(ùë¶_{ùëñ}‚àí\overline{y} )^{2}$ 

Suma explicada de los cuadrados (SEC): $\sum_{ùëñ=1}^{ùëõ}(\hat{ùë¶}‚àí\overline{y} )^{2}$

Suma residual de los cuadrados (SRC): $\sum_{ùëñ=1}^{ùëõ}\hat{u}_{i} ^{2}$ 

Se lo conoce como R cuadrado porque es igual al cuadrado del coeficiente de correlaci√≥n muestral entre $ùë¶_{ùëñ}$ y $\hat{y}_{i}$, y al coeficiente de correlaci√≥n se lo suele denotar con la letra R.

### Propiedades de MCO bajo los supuestos cl√°sicos

#### Consistencia de los par√°metros
**1. Linealidad y dependencia d√©bil.** El modelo es lineal en sus par√°metros, es estacionario y d√©bilmente dependiente. En particular, la ley de los grandes n√∫meros y el teorema del l√≠mite central pueden aplicarse a los promedios muestrales.

**2. Ausencia de multicolinealidad.** No hay variables independientes que sean iguales entre s√≠, combinaciones lineales de las dem√°s o iguales a una constante.

**3. Media condicional cero.** Dadas las variables explicativas para todos los per√≠odos, el valor esperado del error es cero. Las variables explicativas no se correlacionan contempor√°neamente con el error (tampoco con los valores pasados si la serie es d√©bilmente dependiente). Supone que no hay problemas de endogeneidad derivada, por ejemplo, de variables omitidas o error de medici√≥n. Para este supuesto es clave la especificaci√≥n de la forma funcional del modelo.

#### Adem√°s para asumir distribuci√≥n normal se requiere

**4. Homocedasticidad.** Los errores son contempor√°neamente homoced√°sticos, lo que implica que la varianza del error es constante.

**5. Ausencia de correlaci√≥n serial.** Los errores en dos per√≠odos distintos no est√°n correlacionados.

Bajo los supuestos 1 a 5, los estimadores de MCO tienen distribuciones asint√≥ticamente normales. Adem√°s, los errores est√°ndar usuales de MCO, los estad√≠sticos t, los estad√≠sticos F y los estad√≠sticos ML son asint√≥ticamente v√°lidos.

Los modelos con variables explicativas con tendencia satisfacen los supuestos 1 a 5, siempre y cuando sean estacionarios con tendencia determin√≠stica. Mientras las tendencias determin√≠sticas se incluyan en las ecuaciones cuando sea necesario, los procedimientos de inferencia usuales son asint√≥ticamente v√°lidos.


## M√©tricas para la selecci√≥n de modelos

Cuando hay muchos predictores posibles se necesita una estrategia para elegir a los mejores para utilizar en el modelo de regresi√≥n. Una estrategia com√∫n es hacer m√∫ltiples regresiones lineales sobre todos los predictores y descartar todas las variables cuyos p-valores sean mayores a 0,05. Este procedimiento no es correcto porque la significatividad estad√≠stica no siempre indica valor predictivo, y porque los p-valores no son buenos indicadores cuando dos o m√°s predictores est√°n correlacionados uno con el otro (problema de multicolinealidad).

En su lugar, vamos a usar tres medidas de precisi√≥n predictiva:

### 1. R2 ajustado

El R2 convencional tiene como debilidad que no permite controlar por grados de libertad, entonces siempre que agreguemos m√°s variables su valor va a aumentar sin importar que tan relevante sea esa variable. Una alternativa pensada para superar este problema es el R2 ajustado.

\begin{align*}
\overline{R}^{2}=1-(1-R^{2})\frac{T-1}{T-k-1} \\
\end{align*}

Donde ùëá es la cantidad de observaciones y ùëò es la cantidad de predictores. Esto es una mejora del R2, en la medida que no necesariamente va a aumentar con la incorporaci√≥n de nuevos predictores. Usando esta medida, el mejor modelo ser√° aquel con el valor m√°s alto.


### 2. Criterio de informaci√≥n de Akaike (AIC)

Otro m√©todo es el criterio de informaci√≥n de Akaike, que definimos como:

\begin{align*}
AIC=Tlog(\frac{SRC}{T})+2(k+2)  \\
\end{align*}

Donde ùëá es la cantidad de observaciones usadas para la estimaci√≥n y ùëò es la cantidad de predictores en el modelo. Los diferentes paquetes computacionales usan definiciones levemente distintas para el AIC, a pesar de que todos deber√≠an llevar a seleccionar el mismo modelo.
La parte de ùëò+2 en la ecuaci√≥n ocurre porque hay ùëò+2 par√°metros en el modelo: los ùëò coeficientes de los predictores, el intercepto y la varianza de los residuos.
La idea es penalizar el ajuste del modelo con la cantidad de par√°metros que necesitan ser estimados.


### 3. Criterio de informaci√≥n bayesiano de Schwarz (BIC)

Una medida relacionada es el criterio de informaci√≥n bayesiano de Schwarz:

\begin{align*}
BIC=Tlog(\frac{SRC}{T})+(k+2)log(T)  \\
\end{align*}

Al igual que con el AIC, minimizar el BIC tiene como objetivo dar con el mejor modelo. El modelo elegido por el BIC es el mismo que el elegido por el AIC o uno con menos t√©rminos. Esto es porque el BIC penaliza m√°s la cantidad de par√°metros que el AIC. 

### ¬øQu√© m√©trica utilizar?

* Si bien el **R2 ajustado** se usa ampliamente y ha existido durante m√°s tiempo que las otras medidas, su tendencia a seleccionar demasiadas variables predictoras lo hace menos adecuado para la predicci√≥n.

* A muchos estad√≠sticos les gusta usar el **BIC** porque tiene la caracter√≠stica de que si existe un verdadero modelo subyacente, el BIC seleccionar√° ese modelo si se reciben suficientes datos. Sin embargo, rara vez hay un modelo subyacente verdadero, o si lo hubiera, seleccionar ese modelo no necesariamente dar√° los mejores pron√≥sticos (porque las estimaciones de los par√°metros pueden no ser precisas).

* En consecuencia, se suele recomendar utilizar el **AIC** que tiene como objetivo la predicci√≥n. Si el valor de T es lo suficientemente grande, todos conducir√°n al mismo modelo. 



## Resumen conceptual

* El **m√©todo de MCO** es la estrategia m√°s utilizada para estimar los par√°metros poblacionales de un modelo lineal.

* La f√≥rmula de c√°lculo de los estimadores muestrales se deriva del **supuesto de media condicional cero**.

* El **test de hip√≥tesis** es un procedimiento que sirve para juzgar si el valor de un estimador muestral es compatible con el valor del par√°metro poblacional.

* El **p-valor** es una alternativa al test de hip√≥tesis que tiene como ventaja que brinda m√°s informaci√≥n que el m√©todo convencional en el que se elige un nivel de significancia arbitrario. Esta m√©trica indica cu√°l es el menor nivel de significancia al que se habr√≠a rechazado la hip√≥tesis nula.

* Para la **selecci√≥n del mejor modelo** entre varias alternativas se debe utilizar una m√©trica que penalice por la cantidad de par√°metros. Algunas opciones son el R2 ajustado, el AIC o el BIC. El R cuadrado convencional no es un buen indicador porque siempre aumenta con un mayor n√∫mero de par√°metros, y nos puede llevar a elegir un modelo que sobreajuste a los datos muestrales.



# M√≥dulo pr√°ctico


## Paso 1. Limpiamos la memoria y cargamos las librer√≠as

Para comenzar limpiamos la memoria de R-studio con el c√≥gido `rm(list=ls())`. Esto  va a permitir que el script corra m√°s r√°pido. Luego vamos a cargar un conjunto de librer√≠as que utilizaremos en esta clase con el c√≥digo `library()`.

```{r}

#  Limpiamos la memoria
rm(list=ls())

# Abrimos librerias
library(tidyverse)
library(readxl)
library(openxlsx)
library(ggplot2)
library(lubridate)
library(forecast)
library(gdata)
library(ggfortify)
library(kableExtra)

```

## Paso 2. Definimos el directorio y cargamos el archivo

Con el c√≥digo `setwd()` definimos una carpeta desde donde levantaremos los archivos para trabajar y adonde podremos guardar por default los archivos nuevos que generemos. Luego, con el c√≥digo `read.xlsx()` levantamos el archivo de Excel con los datos. Dentro de ese c√≥digo tenemos que especificar el nombre del archivo con su extensi√≥n ("Clase 2.xlsx) y el nombre de la hoja en donde se encuentran los datos que queremos levantar (sheet = "Base").

```{r}

# Establecemos directorio
setwd("C:/Users/mcherkasky/Google Drive/CEPAL/Curso series de tiempo/Clase 2")

# Levantamos archivo desde Excel 
df <- read.xlsx("Clase 2.xlsx",sheet = "Base")

```


## Paso 3. Inspeccionamos los datos

Con la funci√≥n `head()` podemos dar un vistazo a las primeras observaciones. En este caso le pedimos que nos muestre las primeras 5 observaciones.

```{r}

# Inspeccionamos las primeras 5 observaciones
head(df,5)

```

## Paso 4. Definimos la variable tiempo

Definimos la variable tiempo con `as.Date()`. No obstante, cuando levantamos un archivo de Excel puede darse una inconsistencia entre la numeraci√≥n de la fecha de ese programa y la de R. Esto es as√≠ porque R numera la fecha contando desde 01-01-1970 y Excel desde 1899-12-30. Por este motivo tenemos que indicarle a R en qu√© fecha comienza la cuenta para una variable fecha tra√≠da de Excel.

```{r}

# Definimos la variable tiempo
df$Fecha<-as.Date(df$Fecha, origin = "1899-12-30")


```


## Paso 5. Aplicamos transformaciones a las series

Una vez que tenemos la base con las variables con las que queremos trabajar podemos realizar un conjunto de operaciones o transformaciones a estas variables. En este caso nos interesa realizar la diferencia logar√≠tmica de dos variables: el tipo de cambio nominal (TCN) y el √≠ndice de precios al consumidor (IPC)

```{r}

# Creamos variables en diferencia logar√≠tmica
df<-df %>% mutate(dlTCN = log(TCN) - lag(log(TCN)),
                  dlIPC = log(IPC) - lag(log(IPC)))

```

## Paso 6. Creamos variables de series de tiempo

De manera tal de preparar los datos para utilizar los c√≥digos de los modelos, vamos a convertir las variables a series de tiempo. Para ello usamos la funci√≥n `ts()`. Esta funci√≥n la podemos aplicar a variables o incluso a una base de datos entera. Recordar que tenemos que indicar en la funci√≥n el per√≠odo en el cual comienza la serie y su frecuencia. En este caso comienza en el a√±o 2004 y la frecuencia es trimestral (cuatro per√≠odos sobre la base de un a√±o).

```{r}

# Filtramos aquellos valores desde el a√±o 2004
df<-df %>%
    filter(Fecha > "2004-01-01")

# Definimos las series de tiempo
dlTCN <- ts((df$dlTCN), start=c(2004,1), frequency = 4)
dlIPC <- ts((df$dlIPC), start=c(2004,1), frequency = 4)
l.dlIPC <- ts(lag((df$dlIPC)), start=c(2004,1), frequency = 4)

```


## Paso 7. Graficamos las series

Para graficar las series de tipo de cambio y el IPC utilizaremos la libreria "ggfortify" que a su vez est√° basada en la conocida librer√≠a de "ggplot". Notar que en el c√≥digo debemos especificar el nombre del eje horizontal `xlab()`, el nombre del eje vertical `ylab()`, el t√≠tulo del gr√°fico `ggtitle()` y las especificaciones de la leyenda `guides()`.

```{r}

# Graficamos
autoplot(cbind(dlTCN,dlIPC), facets = FALSE)+
  xlab("Fecha") +
  ylab("Diferencia logar√≠tmica") +
  ggtitle("Inflaci√≥n y tipo de cambio") +
  guides(colour=guide_legend(title="Variables"))


```


## Paso 8. Estimamos un modelo por MCO

Una vez preparados los datos vamos a estimar un modelo lineal por el m√©todo de m√≠nimo cuadrados ordinarios, a partir de la funci√≥n `tslm()`. Esta estimaci√≥n la vamos a guardar con el nombre "modelo". En esta funci√≥n tenemos que especificar la variable explicada (dlIPC) y a la derecha del signo "~" todas las variables explicativas (dlTCN+l.dlIPC). Esta funci√≥n va a incorporar por default un intercepto en la estimaci√≥n, a diferencia de otros programas como E-Views en donde tenemos que escribirlo en la ecuaci√≥n.

El modelo que vamos a estimar es el siguiente:

\begin{align*}
\Delta \ln{IPC_{t}} =\beta_{0}+\beta_{1}  \Delta \ln{TCN_{t}}+\beta_{2} \Delta \ln{IPC_{t-1}}+u_{t} \\
\end{align*}

```{r}

# Estimaci√≥n por MCO
modelo <- tslm(dlIPC ~ dlTCN+l.dlIPC)


```

Luego vamos a utilizar la funci√≥n `summary()` para presentar un conjunto de indicadores que se obtienen como resultado de la estimaci√≥n del modelo. La primera columna de la tabla debajo del t√≠tulo "Coefficients" tiene el valor de los par√°metros muestrales (estimadores de los par√°metros poblacionales), la segunda columna tiene los desv√≠os est√°ndar asociados a cada uno de los estimadores, la tercera columna tiene los estad√≠sticos de prueba de la distribuci√≥n T de Student (valores de la primera columna dividos por los valores de la segunda), y la columna 4 tiene los p-valores (menor nivel de significancia al que se habr√≠a rechazado la hip√≥tesis nula). A su vez, debajo de la tabla podemos observar el valor del desv√≠o est√°ndar del residuo, y el R-cuadrado de la regresi√≥n.

```{r}

# Presentaci√≥n de los resultados
summary(modelo)

```

## Paso 9. Calculamos los intervalos de confianza

Tomando el coeficiente asociado al tipo de cambio y su desv√≠o est√°ndar, vamos a obtener el intervalo de confianza para este par√°metro conocido como *pass-through*. De acuerdo a estas estimaciones, el pass-through se encontrar√≠a entre 0.10 y 0.22 a un nivel de confianza del 95%.

```{r}

# Intervalo de confiaza al 95%
passthrough_puntual<-coef(summary(modelo))[2,1]
passthrough_superior<-coef(summary(modelo))[2,1]+1.96*coef(summary(modelo))[2,2]
passthrough_inferior<-coef(summary(modelo))[2,1]-1.96*coef(summary(modelo))[2,2]

passthrough_superior
passthrough_inferior

```



## Paso 10. Calculamos m√©tricas para la selecci√≥n de variables

Vamos a estimar tres combinaciones posibles de un modelo que tenga como variables explicativas de la inflaci√≥n al tipo de cambio y a la inflaci√≥n pasada para evaluar cu√°l es el que ajusta mejor y por tanto cu√°les son las variables que deberiamos considerar. Como ya vimos, el R cuadrado no es un buen indicador: siempre va a mejorar cu√°ntas m√°s variables incorporemos. De forma alternativa tenemos al R cuadrado ajustado, el criterio de Akaike (AIC) y el criterio de informaci√≥n bayesiano de Schwarz (BIC).


```{r}

# Selecci√≥n de variables para mejorar la proyecci√≥n
modelo1 <- tslm(dlIPC ~ dlTCN)
modelo2 <- tslm(dlIPC ~ l.dlIPC)
modelo3 <- tslm(dlIPC ~ dlTCN+l.dlIPC)

# C√°lculo detallado
t=length(dlIPC)
k=length(coefficients(modelo1))-1
resid=dlIPC-fitted.values(modelo1) # Alternativa 1
resid=residuals(modelo1) # Alternativa 2

SCR=sum((resid)^2)
R2<-sum((fitted.values(modelo1)-mean(dlIPC))^2)/sum((dlIPC-mean(dlIPC))^2)
R2A<-1-(1-R2)*(t-1)/(t-k-1)
AIC=t*log(SCR/t)+2*(k+2)
AICc=AIC+(2*(k+2)*(k+3)/(t-k-3))
BIC=t*log(SCR/t)+(k+2)*log(t)


```

Estos mismos indicadores los podemos obtener de manera m√°s sencilla con el c√≥digo `CV()`. Entre par√©ntesis vamos a introducir el nombre que le dimos al objeto del modelo. Luego, vamos a construir una tabla con todos los resultados de manera tal de poder comparar todos los valores obtenidos. Se puede ver que el modelo que obtiene el mejor resultado es el tercero: tiene los menores valores del AIC y BIC, y el mayor valor del R-cuadrado ajustado.

```{r}

# Tabla con resultados ordenados
tabla<-data.frame(cbind(c(1,0,1),c(0,1,1))) %>%
  rename("TCN"=1,"Inercia"=2) %>%
  cbind(rbind(CV(modelo1),CV(modelo2),CV(modelo3)))

kable(tabla, align=rep('c', 5), format.args = list(big.mark = ".")) %>% 
  kable_styling(bootstrap_options = c("striped", "hover"), font_size = 14)

```

# Referencias

* **Enders**, W. (2008). Applied econometric time series. John Wiley & Sons.

* **Hyndman**, R.J., & **Athanasopoulos**, G. (2018). Forecasting: principles and practice, 2nd edition, OTexts: Melbourne, Australia. OTexts.com/fpp2.

* **Wooldridge**, J. M. (2015). Introductory econometrics: A modern approach. Cengage learning.







  

  
